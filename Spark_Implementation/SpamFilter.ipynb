{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.0.0-bin-hadoop2.7')\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('spam').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('../datasets_483_982_spam.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- v1: string (nullable = true)\n",
      " |-- v2: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+----+----+----+\n",
      "|  v1|                  v2| _c2| _c3| _c4|\n",
      "+----+--------------------+----+----+----+\n",
      "| ham|Go until jurong p...|null|null|null|\n",
      "| ham|Ok lar... Joking ...|null|null|null|\n",
      "|spam|Free entry in 2 a...|null|null|null|\n",
      "| ham|U dun say so earl...|null|null|null|\n",
      "| ham|Nah I don't think...|null|null|null|\n",
      "|spam|FreeMsg Hey there...|null|null|null|\n",
      "| ham|Even my brother i...|null|null|null|\n",
      "| ham|As per your reque...|null|null|null|\n",
      "|spam|WINNER!! As a val...|null|null|null|\n",
      "|spam|Had your mobile 1...|null|null|null|\n",
      "| ham|I'm gonna be home...|null|null|null|\n",
      "|spam|SIX chances to wi...|null|null|null|\n",
      "|spam|URGENT! You have ...|null|null|null|\n",
      "| ham|I've been searchi...|null|null|null|\n",
      "| ham|I HAVE A DATE ON ...|null|null|null|\n",
      "|spam|XXXMobileMovieClu...|null|null|null|\n",
      "| ham|Oh k...i'm watchi...|null|null|null|\n",
      "| ham|Eh u remember how...|null|null|null|\n",
      "| ham|Fine if that��s t...|null|null|null|\n",
      "|spam|England v Macedon...|null|null|null|\n",
      "+----+--------------------+----+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+--------------------+--------------------+\n",
      "|  v1|                  v2|                 _c2|                 _c3|                 _c4|\n",
      "+----+--------------------+--------------------+--------------------+--------------------+\n",
      "|spam|\"Your free ringto...|         PO Box 5249| MK17 92H. 450Ppw...|                null|\n",
      "| ham| \\Wen u miss someone| the person is de...|    why to miss them|\" just Keep-in-to...|\n",
      "| ham|\\HEY HEY WERETHE ...| HOWU DOIN? FOUND...|                null|                null|\n",
      "|spam|SMS. ac sun0819 p...|\" wanted to say h...|                null|                null|\n",
      "| ham|Height of Confide...|this wont even st...|                null|                null|\n",
      "|spam|\"Your free ringto...|         PO Box 5249| MK17 92H. 450Ppw...|                null|\n",
      "| ham|\"Edison has right...|                  GN|                  GE|            GNT:-)\"\"|\n",
      "| ham|\"Height of \\Oh sh...|           .;-):-D\"\"|                null|                null|\n",
      "| ham|\\Hey sorry I didn...|just been in bedb...|                null|                null|\n",
      "| ham|\"Storming msg: We...| bt not his girlf...|                null|                null|\n",
      "| ham|\"Tell you what, i...|      I'll come up\"\"|                null|                null|\n",
      "| ham|\"Single line with...| don't miss ur be...|                null|                null|\n",
      "|spam|0A$NETWORKS allow...| just as a shop h...|                null|                null|\n",
      "| ham|Very hurting n me...|\" But at d end my...|                null|                null|\n",
      "| ham|Painful words- \\I...| the toughest is ...|                null|                null|\n",
      "| ham|My planning usual...| smoke hella weed...|                null|                null|\n",
      "| ham|The fact that you...|\"\"\" not \\\"\"what i...|                null|                null|\n",
      "| ham|\\YEH I AM DEF UP4...|JUST GOT PAYED2DA...|                null|                null|\n",
      "| ham|       \\alright babe| justthought i��d...|                null|                null|\n",
      "| ham|\\CAN I PLEASE COM...|JUST REALLYNEED 2...|U NO THECD ISV.IM...|                null|\n",
      "+----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.na.drop(thresh=3).show()\n",
    "data.na.drop(thresh=3).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill null columns with empty string\n",
    "data = data.na.fill(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all string columns with a SPACE separator\n",
    "\n",
    "data = data.withColumn('full_text', concat_ws(' ',\n",
    "    col('v2'),\n",
    "    col('_c2'),\n",
    "    col('_c3'),\n",
    "    col('_c4'),\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only necessary columns and drop any rows with null values\n",
    "\n",
    "data = data.select(['v1', 'full_text'])\n",
    "data = data.na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol=\"full_text\", outputCol=\"words\", pattern=\"[\\\\w]+\", gaps=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = regexTokenizer.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "If the regex pattern did not match any text in the `full_text`\n",
    "column, that column will have a null value (or `None`). In order\n",
    "to avoid conflict, we must drop those rows.\n",
    "'''\n",
    "\n",
    "tokenized = tokenized.na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = StopWordsRemover(inputCol='words', outputCol='filtered_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = remover.transform(tokenized).select(['v1', 'filtered_words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash Words in Word Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer, StringIndexer, VectorIndexer, HashingTF, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol='v1', outputCol='label').fit(filtered_data).transform(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(inputCol=\"filtered_words\", outputCol=\"features\", vocabSize=100000)\n",
    "\n",
    "final_data = cv.fit(indexer).transform(indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-----+--------------------+\n",
      "|  v1|      filtered_words|label|            features|\n",
      "+----+--------------------+-----+--------------------+\n",
      "| ham|[go, jurong, poin...|  0.0|(8624,[11,16,37,6...|\n",
      "| ham|[ok, lar, joking,...|  0.0|(8624,[0,9,248,37...|\n",
      "|spam|[free, entry, 2, ...|  1.0|(8624,[2,10,23,24...|\n",
      "| ham|[u, dun, say, ear...|  0.0|(8624,[0,57,84,86...|\n",
      "| ham|[nah, think, goes...|  0.0|(8624,[53,139,369...|\n",
      "|spam|[freemsg, hey, da...|  1.0|(8624,[9,15,21,26...|\n",
      "| ham|[even, brother, l...|  0.0|(8624,[15,130,288...|\n",
      "| ham|[per, request, me...|  0.0|(8624,[149,162,30...|\n",
      "|spam|[winner, valued, ...|  1.0|(8624,[1,65,82,15...|\n",
      "|spam|[mobile, 11, mont...|  1.0|(8624,[0,1,10,31,...|\n",
      "| ham|[m, gonna, home, ...|  0.0|(8624,[3,22,29,34...|\n",
      "|spam|[six, chances, wi...|  1.0|(8624,[6,18,21,24...|\n",
      "|spam|[urgent, won, 1, ...|  1.0|(8624,[10,24,26,5...|\n",
      "| ham|[ve, searching, r...|  0.0|(8624,[45,77,85,1...|\n",
      "| ham|      [date, sunday]|  0.0|(8624,[482,679],[...|\n",
      "|spam|[xxxmobilemoviecl...|  1.0|(8624,[24,37,80,1...|\n",
      "| ham|[oh, k, m, watching]|  0.0|(8624,[3,42,63,27...|\n",
      "| ham|[eh, u, remember,...|  0.0|(8624,[0,2,72,74,...|\n",
      "| ham|[fine, way, u, fe...|  0.0|(8624,[0,73,91,13...|\n",
      "|spam|[england, v, mace...|  1.0|(8624,[4,24,26,40...|\n",
      "+----+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Test Data\n",
    "\n",
    "* 60/40 split, Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = final_data.randomSplit([0.6, 0.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes()\n",
    "\n",
    "# train the model\n",
    "model = nb.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+--------------------+--------------------+--------------------+----------+\n",
      "| v1|      filtered_words|label|            features|       rawPrediction|         probability|prediction|\n",
      "+---+--------------------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|ham|                  []|  0.0|        (8624,[],[])|[-0.1502082941297...|[0.86052871467639...|       0.0|\n",
      "|ham|                  []|  0.0|        (8624,[],[])|[-0.1502082941297...|[0.86052871467639...|       0.0|\n",
      "|ham|                  []|  0.0|        (8624,[],[])|[-0.1502082941297...|[0.86052871467639...|       0.0|\n",
      "|ham|                  []|  0.0|        (8624,[],[])|[-0.1502082941297...|[0.86052871467639...|       0.0|\n",
      "|ham|                  []|  0.0|        (8624,[],[])|[-0.1502082941297...|[0.86052871467639...|       0.0|\n",
      "|ham|[1, number, 2, go...|  0.0|(8624,[2,5,26,43,...|[-91.373094987353...|[0.99995448134812...|       0.0|\n",
      "|ham|[1, reach, home, ...|  0.0|(8624,[1,26,29,32...|[-25.975141564270...|[0.94427763138499...|       0.0|\n",
      "|ham|[1, tension, face...|  0.0|(8624,[2,6,7,8,26...|[-244.52825706098...|[0.99999999999999...|       0.0|\n",
      "|ham| [10, min, later, k]|  0.0|(8624,[42,51,124,...|[-28.827252257701...|[0.99711426237683...|       0.0|\n",
      "|ham|[140, ard, rest, ...|  0.0|(8624,[2,6,397,45...|[-92.266649685985...|[0.97282223024231...|       0.0|\n",
      "|ham|[2, docs, appoint...|  0.0|(8624,[2,3,54,137...|[-105.29091850085...|[0.99957236283113...|       0.0|\n",
      "|ham|[2, laptop, noe, ...|  0.0|(8624,[2,25,161,2...|[-68.531550394648...|[0.99999588804486...|       0.0|\n",
      "|ham|        [26th, july]|  0.0|(8624,[2164,3752]...|[-20.942547438261...|[0.29299879860132...|       1.0|\n",
      "|ham|[2mro, coming, gy...|  0.0|(8624,[174,818,98...|[-43.305790200943...|[0.99928496854825...|       0.0|\n",
      "|ham|   [3, pa, selected]|  0.0|(8624,[70,294,346...|[-24.174770325984...|[0.67122108599538...|       0.0|\n",
      "|ham|[4, let, go, bill...|  0.0|(8624,[6,11,100,9...|[-37.171210700946...|[0.97854348379893...|       0.0|\n",
      "|ham|[5, 2, work, timing]|  0.0|(8624,[2,75,128,1...|[-28.105787533687...|[0.99633814759442...|       0.0|\n",
      "|ham|[5, nights, nt, s...|  0.0|(8624,[128,264,48...|[-68.338366723234...|[0.99977813019379...|       0.0|\n",
      "|ham|        [6, get, ok]|  0.0|(8624,[5,9,186],[...|[-17.797840685965...|[0.99630716928553...|       0.0|\n",
      "|ham|[7, wonders, worl...|  0.0|(8624,[4,14,56,99...|[-195.53140015337...|[0.99999995930822...|       0.0|\n",
      "+---+--------------------+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select example rows to display.\n",
    "predictions = model.transform(test_data)\n",
    "predictions.show()\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 97.76902887139107%\n"
     ]
    }
   ],
   "source": [
    "print(f'Test set accuracy = {accuracy*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array_contains, explode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Spam Words\n",
    "\n",
    "In this section, the goal is to ensure the model is working correctly. By checking the words that appear most frequently in spam emails and words that appear most frequently in *predicted* spam emails, we can verify that the model is behaving as expected (to a degree). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Words that Occur Most Frequently in Spam Emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  word|count|\n",
      "+------+-----+\n",
      "|  call|  355|\n",
      "|  free|  224|\n",
      "|     2|  207|\n",
      "|     u|  174|\n",
      "|   txt|  163|\n",
      "|    ur|  144|\n",
      "|     4|  137|\n",
      "|mobile|  127|\n",
      "|  text|  125|\n",
      "|  stop|  123|\n",
      "| claim|  113|\n",
      "|     1|  112|\n",
      "| reply|  104|\n",
      "|   www|   98|\n",
      "| prize|   93|\n",
      "|   get|   86|\n",
      "|   won|   76|\n",
      "|  cash|   76|\n",
      "|    uk|   74|\n",
      "|  150p|   71|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter data for spam-only emails\n",
    "spam_emails = final_data.filter(final_data.label == 1)\n",
    "\n",
    "# Split out list of words and create a row for every word in the list in each row\n",
    "spam_words = spam_emails.select(final_data.v1, explode(final_data.filtered_words).alias('word'))\n",
    "\n",
    "# Group by words and count\n",
    "spam_words_count = spam_words.groupBy('word').count()\n",
    "\n",
    "# Order by most frequent words in spam emails\n",
    "spam_words_count.orderBy(spam_words_count['count'].desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Words that Occur Most Frequently in Spam Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  word|count|\n",
      "+------+-----+\n",
      "|  call|  129|\n",
      "|  free|   94|\n",
      "|     2|   74|\n",
      "|     u|   67|\n",
      "|   txt|   62|\n",
      "|    ur|   53|\n",
      "|     4|   52|\n",
      "|mobile|   51|\n",
      "| claim|   49|\n",
      "|  text|   47|\n",
      "| prize|   41|\n",
      "| reply|   41|\n",
      "|   www|   39|\n",
      "|  stop|   39|\n",
      "|     1|   37|\n",
      "| nokia|   35|\n",
      "|   won|   32|\n",
      "|   new|   32|\n",
      "|   get|   31|\n",
      "|    uk|   30|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter predictions for spam only predictions\n",
    "spam_predictions = predictions.filter(predictions.prediction == 1)\n",
    "\n",
    "# Split out list of words and create a row for every word in the list in each row\n",
    "spam_pred_words = spam_predictions.select(predictions.v1, explode(predictions.filtered_words).alias('word'))\n",
    "\n",
    "# Group by words and count\n",
    "spam_pred_words_count = spam_pred_words.groupBy('word').count()\n",
    "\n",
    "# Order by most frequent words in spam predicitons\n",
    "spam_pred_words_count.orderBy(spam_pred_words_count['count'].desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
